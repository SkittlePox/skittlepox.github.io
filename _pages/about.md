---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I'm Ben, a fourth-year PhD candidate in Computer Science at Brown University advised by [George Konidaris](https://cs.brown.edu/~gdk/). My research focuses on the **language grounding problem**, and I draw inspiration from linguistics, cognitive science, philosophy of mind/language, and semiotics.

I'm honored to be a recipient of the [NSF Graduate Research Fellowship](https://cs.brown.edu/news/2022/05/20/five-brown-cs-students-and-alums-receive-nsf-graduate-research-fellowships/) and the Brown University [Morgan Edwards](https://en.wikipedia.org/wiki/Morgan_Edwards) Fellowship. In 2023, I had the privilege of serving as the lead organizer for the [Brown Robotics Talk Series](https://yzylmc.github.io/brown-lab-talks/). I was also a founding member of the [Brown AI Safety Team](https://www.baist.ai/). I'm also a proud alum of [Brooklyn Technical High School](https://en.wikipedia.org/wiki/Brooklyn_Technical_High_School)!

### Research Philosophy

I've published a full statement covering my research agenda [on my substack](https://open.substack.com/pub/superspeeg/p/we-should-evolve-language-models?r=q8xul&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true), but here's the TLDR:

The main thesis motivating my work is that language was invented by humans to reason about and describe their subjective experience of the world. To ground language, we must ultimately render it in terms of perception and action‚Äîthe machinery of decision-making. At a high level, **my entire research agenda is about how to achieve this rendering.**

My earlier works achieve this rendering using a [formal language for describing Markov Decision Processes](http://rlang.ai/master/) as a semantic representation. My current work uses multi-agent RL and Bayesian inference to explore the conditions by which artificial agents will invent human-like languages about their environment. I hypothesize that we can simulate core language _acquisition_, _invention_, and _understanding_ faculties that are responsible for natural languages in humans, which we can potentially apply to autonomously inventing artificial languages that rival the expressivity of human language.

I maintain a (sometimes outdated) record of my academic readings, with [papers cataloged here](https://www.zotero.org/benjamin-spiegel/library) and [books listed here](https://speeg.notion.site/5de77c8575634b90b4699d0f185295cb?v=a884d376bf6b4e5a99a27e9aa2e98698&pvs=4).

## News
- **AY '25-'26:** I'm on a talk circuit, giving "A Path to Language Understanding: Grounding Language to Markov Decision Processes".
  - **February, 2026:** I gave a talk at Stanford's Department of Psychology in the Cognitive Tools Lab (host: Judy Fan).
  - **February, 2026:** I a talk at UC Berkeley in the Center for Human-Compatible Artificial Intelligence (host: Cam Allen).
  - **November, 2025:** I gave two talks at U Edinburgh in the Centre For Language Evolution (host: Kenny Smith) and the School of Informatics (host: Dave Abel).
  - **October, 2025:** I gave a talk at UMass Amherst in the Autonomous Learning Lab (host: Philip Thomas).
  - **October, 2025:** I gave talks at MIT in the Computational Cognitive Science lab (host: Josh Tenenbaum) and the Computational Psycholinguistics Lab (host: Roger Levy).
- **Jul 31st, 2025:** I gave my first oral presentation in the Computational Modeling 1 Talks session at CogSci 2025! Here's [a quick summary](https://open.substack.com/pub/superspeeg/p/a-grounded-and-naturalistic-approach?r=q8xul&utm_campaign=post&utm_medium=web&showWelcomeOnShare=false) of the paper on substack.
- **Jun 4th, 2025:** My first position piece titled "AGI Is Not Multimodal" was [published at The Gradient](https://thegradient.pub/agi-is-not-multimodal/). Here's a short [tweet thread](https://x.com/superspeeg/status/1930277179121905815) about it, and a [Hacker News thread](https://news.ycombinator.com/item?id=44181613) that popped up. It was also [written about in TLDR AI](https://arc.net/l/quote/gertyzxg). I wrote [a short substack post](https://superspeeg.substack.com/p/a-grounded-and-naturalistic-approach) describing how it connects to my broader research arc.
- **Apr 24th, 2025:** My recent CogSci paper was [covered by Perplexity](https://www.perplexity.ai/page/new-study-finds-that-ai-learns-u6myMBdRSX6Rb.SCTD8B9g) and [mentioned in WIRED](https://www.wired.com/story/ai-lab-amazon-launches-vulcan-a-robot-that-can-feel/), after [I tweeted](https://x.com/superspeeg/status/1914691313318105305) about it:
  <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Why did only humans invent graphical systems like writing?
üß†‚úçÔ∏è<br><br>In our new paper at <a href="https://twitter.com/cogsci_soc?ref_src=twsrc%5Etfw">@cogsci_soc</a>, we explore how agents learn to communicate using a model of pictographic signification similar to human proto-writing. üßµüëá <a href="https://t.co/3NtveUk4hu">pic.twitter.com/3NtveUk4hu</a></p>&mdash; Benjamin Spiegel (@superspeeg) <a href="https://twitter.com/superspeeg/status/1914691313318105305?ref_src=twsrc%5Etfw">April 22, 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
- **Apr 4th, 2025:** My CogSci 2025 submission titled [_Visual Theory of Mind Enables the Invention of Proto-Writing_](https://arxiv.org/abs/2502.01568) was accepted for oral presentation.

### Personal Interests

I enjoy reading, watching movies, playing ultimate frisbee, playing piano, listening to music, and solving Rubik's Cubes (my personal best for a 3-by-3 is 9.58s, and my best Ao5 was ~12s). I organize and facilitate a bi-weekly Salon-style discussion group for grad students at Brown called [Junto](http://www.benjamin-franklin-history.org/junto-club/). I also practice mindfulness meditation, enjoy the [Making Sense podcast](https://www.samharris.org/podcasts) (though do not agree with Sam on all issues), and was briefly a [frequenter of LessWrong](https://www.lesswrong.com/users/benjamin-spiegel).
